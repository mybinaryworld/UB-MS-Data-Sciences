{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_path = \"/Users/abhishekkumar/Documents/MS_UB/Fall_18/ESL506_StatisticalDataMiningI/Project/SIGNATE/translated/\"\n",
    "\n",
    "train = pd.read_table(os.path.join(data_path,\"'ttrain.tsv'.txt\"))\n",
    "test = pd.read_table(os.path.join(data_path,\"'ttest.tsv'.txt\"))\n",
    "hotlink = pd.read_table(os.path.join(data_path,\"'thotlink.tsv'.txt\"))\n",
    "nightley = pd.read_table(os.path.join(data_path,\"'nightley.tsv'.txt\"))\n",
    "colopl = pd.read_table(os.path.join(data_path,\"'tcolopl.tsv'.txt\"))\n",
    "jorudan = pd.read_table(os.path.join(data_path,\"tjorudan.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>epark</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Akan Megumi National Park</td>\n",
       "      <td>11028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>Akan Megumi National Park</td>\n",
       "      <td>11153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Akan Megumi National Park</td>\n",
       "      <td>12343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Akan Megumi National Park</td>\n",
       "      <td>6732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>Akan Megumi National Park</td>\n",
       "      <td>4877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime                      epark  visitors\n",
       "0  2015-01-01  Akan Megumi National Park     11028\n",
       "1  2015-01-02  Akan Megumi National Park     11153\n",
       "2  2015-01-03  Akan Megumi National Park     12343\n",
       "3  2015-01-04  Akan Megumi National Park      6732\n",
       "4  2015-01-05  Akan Megumi National Park      4877"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekkumar/anaconda3/envs/signate/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/abhishekkumar/anaconda3/envs/signate/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype bool, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/abhishekkumar/anaconda3/envs/signate/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/abhishekkumar/anaconda3/envs/signate/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype bool, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "#Transforming Training Data\n",
    "#####################################################################\n",
    "#One hot encoding for parks\n",
    "train_df = pd.DataFrame()\n",
    "train_df[\"Akan\"] = train[\"epark\"] == \"Akan Megumi National Park\"\n",
    "train_df[\"Aso\"] = train[\"epark\"] == \"Aso Kuju National Park\"\n",
    "train_df[\"Ise\"] = train[\"epark\"] == \"Ise Shima National Park\"\n",
    "train_df[\"Kerama\"] = train[\"epark\"] == \"Kerama islands national park\"\n",
    "train_df[\"Kirishima\"] = train[\"epark\"] == \"Kirishima Jinjiang Bay National Park\"\n",
    "train_df[\"Nikko\"] = train[\"epark\"] == \"Nikko National Park\"\n",
    "train_df[\"Oyama\"] = train[\"epark\"] == \"Oyama Oki National Park\"\n",
    "train_df[\"Towada\"] = train[\"epark\"] == \"Towada Hachimantai National Park\"\n",
    "\n",
    "#\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "#Creating new features with datetime\n",
    "train_df[\"dayofweek\"] = train['datetime'].dt.dayofweek\n",
    "train_df[\"dayofweek\"] = train_df[\"dayofweek\"].astype(object)\n",
    "train_df[\"month\"] = train['datetime'].dt.month\n",
    "train_df[\"month\"] = train_df[\"month\"].astype(object)\n",
    "train_df[\"year\"] = train['datetime'].dt.year\n",
    "train_df[\"year\"] = train_df[\"year\"].astype(object)\n",
    "train_df[\"day\"] = train['datetime'].dt.day\n",
    "train_df[\"day\"] = train_df[\"day\"].astype(object)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#Transforming Test Data\n",
    "#############################################################################\n",
    "#One hot encoding for parks\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"Akan\"] = test[\"epark\"] == \"Akan Megumi National Park\"\n",
    "test_df[\"Aso\"] = test[\"epark\"] == \"Aso Kuju National Park\"\n",
    "test_df[\"Ise\"] = test[\"epark\"] == \"Ise Shima National Park\"\n",
    "test_df[\"Kerama\"] = test[\"epark\"] == \"Kerama islands national park\"\n",
    "test_df[\"Kirishima\"] = test[\"epark\"] == \"Kirishima Jinjiang Bay National Park\"\n",
    "test_df[\"Nikko\"] = test[\"epark\"] == \"Nikko National Park\"\n",
    "test_df[\"Oyama\"] = test[\"epark\"] == \"Oyama Oki National Park\"\n",
    "test_df[\"Towada\"] = test[\"epark\"] == \"Towada Hachimantai National Park\"\n",
    "\n",
    "#\n",
    "test['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "#Creating new features with datetime\n",
    "test_df[\"dayofweek\"] = test['datetime'].dt.dayofweek\n",
    "test_df[\"dayofweek\"] = test_df[\"dayofweek\"].astype(object)\n",
    "test_df[\"month\"] = test['datetime'].dt.month\n",
    "test_df[\"month\"] = test_df[\"month\"].astype(object)\n",
    "test_df[\"year\"] = test['datetime'].dt.year\n",
    "test_df[\"year\"] = test_df[\"year\"].astype(object)\n",
    "test_df[\"day\"] = test['datetime'].dt.day\n",
    "test_df[\"day\"] = test_df[\"day\"].astype(object)\n",
    "\n",
    "\n",
    "###################\n",
    "#Scaling test and training features\n",
    "##################\n",
    "X_train_scaled = scaler.fit_transform(train_df) \n",
    "X_test_scaled = scaler.fit_transform(test_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "model = xgb.fit(X_train_scaled, train[\"visitors\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2557.4943176810866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "score = np.mean(abs(y_pred - train[\"visitors\"]))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Akan</th>\n",
       "      <th>Aso</th>\n",
       "      <th>Ise</th>\n",
       "      <th>Kerama</th>\n",
       "      <th>Kirishima</th>\n",
       "      <th>Nikko</th>\n",
       "      <th>Oyama</th>\n",
       "      <th>Towada</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Akan    Aso    Ise  Kerama  Kirishima  Nikko  Oyama  Towada dayofweek  \\\n",
       "0  True  False  False   False      False  False  False   False         3   \n",
       "1  True  False  False   False      False  False  False   False         4   \n",
       "2  True  False  False   False      False  False  False   False         5   \n",
       "3  True  False  False   False      False  False  False   False         6   \n",
       "4  True  False  False   False      False  False  False   False         0   \n",
       "\n",
       "  month  year day  \n",
       "0     1  2015   1  \n",
       "1     1  2015   2  \n",
       "2     1  2015   3  \n",
       "3     1  2015   4  \n",
       "4     1  2015   5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5848.000000\n",
       "mean      7186.736149\n",
       "std       8791.087517\n",
       "min          0.000000\n",
       "25%        346.000000\n",
       "50%       4214.500000\n",
       "75%      11103.750000\n",
       "max      87008.000000\n",
       "Name: visitors, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"visitors\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.random.randint(0,5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aa.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 4, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.append(5)\n",
    "aa = np.asarray(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 3, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signate",
   "language": "python",
   "name": "signate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
